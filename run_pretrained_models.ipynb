{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\nathan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_vader(sentiment):\n",
    "    if sentiment > 0.05:\n",
    "        return 1\n",
    "    elif sentiment < -0.05:\n",
    "        return -1\n",
    "    else:\n",
    "       return 0\n",
    "\n",
    "def categorize_textblob(sentiment):\n",
    "    if sentiment> 0.05:\n",
    "        return 1\n",
    "    elif sentiment < -0.05:\n",
    "        return -1\n",
    "    else:\n",
    "       return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets = pd.read_csv(\"manual_labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets = labeled_tweets[labeled_tweets[\"label\"] != np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tweets = labeled_tweets.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets = labeled_tweets[(labeled_tweets[\"label\"] == \"1\") | (labeled_tweets[\"label\"] == \"0\") | (labeled_tweets[\"label\"] == \"-1\" )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nathan\\AppData\\Local\\Temp/ipykernel_22520/422618980.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  good_tweets[\"label\"] = good_tweets[\"label\"].apply(int)\n"
     ]
    }
   ],
   "source": [
    "good_tweets[\"label\"] = good_tweets[\"label\"].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets = good_tweets.set_index(\"tweet_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process tweets to remove @ and urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(text):\n",
    "    text = re.sub(r\"(?:\\@+|https?\\://)\\S+|\", \"\", text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets[\"tweet\"] = good_tweets[\"orig_tweet\"].apply(lambda x : process_tweet(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run vader to find sentiment on tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets[\"vader\"] = good_tweets[\"tweet\"].apply(sid.polarity_scores)\n",
    "good_tweets[\"vader\"] = good_tweets[\"vader\"].apply(lambda x : x[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets[(good_tweets[\"vader\"] < -0.9) & (good_tweets[\"label\"] == 1)].to_csv(\"vader_big_wrong.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets[\"vader_category\"] = good_tweets[\"vader\"].apply(categorize_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    699\n",
       "-1    492\n",
       " 0    398\n",
       "Name: vader_category, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_tweets[\"vader_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.60      0.63       556\n",
      "           0       0.36      0.40      0.38       353\n",
      "           1       0.60      0.62      0.61       680\n",
      "\n",
      "    accuracy                           0.56      1589\n",
      "   macro avg       0.54      0.54      0.54      1589\n",
      "weighted avg       0.57      0.56      0.57      1589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(good_tweets[\"label\"], good_tweets[\"vader_category\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run textblob to find sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets[\"textblob\"] = good_tweets[\"tweet\"].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets[\"textblob_category\"] = good_tweets[\"textblob\"].apply(categorize_textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    700\n",
       " 0    594\n",
       "-1    295\n",
       "Name: textblob_category, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_tweets[\"textblob_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.59      0.31      0.41       556\n",
      "           0       0.25      0.42      0.31       353\n",
      "           1       0.53      0.54      0.53       680\n",
      "\n",
      "    accuracy                           0.44      1589\n",
      "   macro avg       0.46      0.43      0.42      1589\n",
      "weighted avg       0.49      0.44      0.44      1589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(good_tweets[\"label\"], good_tweets[\"textblob_category\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bag of words vectorization naieve bayes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from https://www.analyticsvidhya.com/blog/2022/07/sentiment-analysis-using-python/\n",
    "#Loading the Dataset\n",
    "data = good_tweets\n",
    "\n",
    "#Pre-Prcoessing and Bag of Word Vectorization using Count Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "#cv = TfidfVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "\n",
    "text_counts = cv.fit_transform(data['tweet'])\n",
    "#Splitting the data into trainig and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, data['label'], test_size=0.25, random_state=random.randint(0,100000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)\n",
    "#Caluclating the accuracy score of the model\n",
    "from sklearn import metrics\n",
    "bayes_pred = MNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(bayes_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.82      0.75       125\n",
      "           0       0.61      0.31      0.41        98\n",
      "           1       0.69      0.81      0.75       175\n",
      "\n",
      "    accuracy                           0.69       398\n",
      "   macro avg       0.67      0.64      0.64       398\n",
      "weighted avg       0.68      0.69      0.66       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, bayes_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets[\"bayes_category\"] = MNB.predict(cv.transform(good_tweets[\"tweet\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run linear regression with same tokenized data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression()\n",
    "regression = lr_model.fit(X_train, Y_train)\n",
    "lr_predications = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.70      0.71       125\n",
      "           0       0.57      0.42      0.48        98\n",
      "           1       0.71      0.83      0.77       175\n",
      "\n",
      "    accuracy                           0.69       398\n",
      "   macro avg       0.67      0.65      0.65       398\n",
      "weighted avg       0.68      0.69      0.68       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, lr_predications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegexpTokenizer(pattern='[a-zA-Z0-9]+', gaps=False, discard_empty=True, flags=re.UNICODE|re.MULTILINE|re.DOTALL)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC().fit(X_train, Y_train)\n",
    "svc_pref = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.66      0.72       125\n",
      "           0       0.55      0.28      0.37        98\n",
      "           1       0.64      0.90      0.75       175\n",
      "\n",
      "    accuracy                           0.67       398\n",
      "   macro avg       0.66      0.61      0.61       398\n",
      "weighted avg       0.67      0.67      0.65       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, svc_pref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6296699073230545"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "svc_crossval = cross_val_score(SVC(), text_counts, data[\"label\"], cv=20, scoring='f1_weighted')\n",
    "sum(svc_crossval) / len(svc_crossval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6559774168362332"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB_crossval = cross_val_score(MNB, text_counts, data[\"label\"], cv=20, scoring='f1_weighted')\n",
    "sum(MNB_crossval) / len(MNB_crossval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6559774168362332"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_crossval = cross_val_score(lr_model, text_counts, data[\"label\"], cv=20, scoring='f1_weighted')\n",
    "sum(MNB_crossval) / len(MNB_crossval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_tweets.to_csv(\"tweets_with_label_and_pretrained.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
